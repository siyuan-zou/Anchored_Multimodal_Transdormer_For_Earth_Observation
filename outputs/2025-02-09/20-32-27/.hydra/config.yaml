trainer:
  _target_: pytorch_lightning.Trainer
  val_check_interval: 1.0
  devices: ${machine.devices}
  accelerator: ${machine.accelerator}
  gradient_clip_val: 1
  log_every_n_steps: 1000
  num_nodes: ${machine.num_nodes}
  precision: ${machine.precision}
logger:
  _target_: pytorch_lightning.loggers.WandbLogger
  mode: online
  project: adapt
  save_dir: ${paths.logs}/wandb
  name: adapt-TreeSat
  log_model: true
seed: 1999
classification_partition: 0.1
max_epochs: 20
test: true
log: true
checkpoints: true
contrastive: true
anchoring: true
clf: true
cv: 1
grid: {}
multimodal:
  path_labels: StressID_Dataset/labels_modalities.csv
  modalities:
  - aerial
  - s2
  - s1-asc
  hyperparams:
    batch_size: 32
    num_workers: 5
    sliding_window: true
  keep_missing: true
  classcification_partition: ${classification_partition}
  partition: 1.0
  mono_strict: false
  train_transform:
  - p: 0.0
  - size: 300
  val_transform:
  - p: 0.0
  - size: 300
  test_transform:
  - p: 0.0
  - size: 300
  classes:
  - Abies
  - Acer
  - Alnus
  - Betula
  - Cleared
  - Fagus
  - Fraxinus
  - Larix
  - Picea
  - Pinus
  - Populus
  - Prunus
  - Pseudotsuga
  - Quercus
  - Tilia
model:
  encoders:
    type:
    - TreeSAT
    aerial:
      patch_size: 50
      in_chans: 4
      embed_dim: 256
      bias: false
      res: true
      gp_norm: 4
    s2:
      in_channels: 10
      n_head: 16
      d_k: 8
      mlp:
      - 256
      - 512
      - 256
      mlp_in:
      - 32
      - 128
      - 256
      dropout: 0.2
      T: 367
      in_norm: true
      positional_encoding: true
    s1-asc:
      in_channels: 2
      n_head: 16
      d_k: 8
      mlp:
      - 256
      - 512
      - 256
      mlp_in:
      - 32
      - 128
      - 256
      dropout: 0.2
      T: 367
      in_norm: false
      positional_encoding: true
    pretrained: true
    projection: true
    freeze: false
    n_dims_audio: 512
    ts_setting:
      hidden: 16
      bottleneck: false
      kernel: 200
      depth: 1
      rezero: false
  anchor: aerial
  transformer:
    _target_: src.models.modules.attention.Attention
    d_model: 64
    dropout: 0.2
    n_heads: 4
    n_blocks: 1
  supervised_loss:
    max_epochs: ${max_epochs}
    lr: 0.0001
    weight_decay: 0.05
    warmup: 4
    min_lr: 1.0e-08
    sch: true
  contrastive_loss:
    max_epochs: ${max_epochs}
    lr: 0.0001
    weight_decay: 0.0001
    warmup: 4
    min_lr: 1.0e-08
    learnable_scale: true
    sch: true
    modality_dropout: true
    temperature: 0.07
    temperature_max: 1
    temperature_min: 0.07
    ts_augment: true
    cos: false
    gamma: 0.05
    noise_sigma: 0.1
  anchoring_loss:
    max_epochs: ${max_epochs}
    lr: 0.001
    weight_decay: 0.0001
    cos: true
    learnable_scale: false
    warmup: 4
    min_lr: 1.0e-08
    sch: true
    temperature_max: 1
    temperature_min: 0.07
    period: 100
    gamma: 0.05
machine:
  devices: 1
  num_workers: 10
  progress_bar_refresh_rate: 2
  sync_batchnorm: false
  accelerator: gpu
  precision: 32
  num_nodes: 1
  eval_gpu_type: null
  strategy: single_device
paths:
  data: /Data/zou.siyuan/ADAPT/misc/TreeSat
  misc: /Data/zou.siyuan/ADAPT/misc
  logs: /Data/zou.siyuan/ADAPT/logs
